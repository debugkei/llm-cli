# llm-cli
This project allows CLI use of LLMs through llama.cpp server.

# Features
* Get responses in terminal.
* Input files and whole directories into LLMs for them to read.
* Execute commands generated by LLMs right in the terminal

# Dependencies
## To download all
> pip install -r requirements.txt
## List
* llama-cpp-python (python package)

# Development
### This project is actively developed right now.
* No releases.
* No pull requests will be accepted.
